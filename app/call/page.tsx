"use client";
import {
  BigXIcon,
  LeftChevronIcon,
  MicIcon,
  ProfileIcon,
} from "@/components/svg";
import { COLORS } from "@/styles/color";
import { TYPOGRAPHY } from "@/styles/typography";
import styled from "@emotion/styled";
import { useRouter } from "next/navigation";
import { useEffect, useRef, useState } from "react";
import { DotLottieReact } from "@lottiefiles/dotlottie-react";
import { useMutation } from "@tanstack/react-query";
import customAxios from "@/lib/axios";
import Typewriter from "@/components/effect/Typewriter";
import { useAuthStore } from "@/stores/authStore";

type FirstChat = {
  sessionId: string;
  speech: string;
  turn: number;
  voiceSpeech: string;
};

type SpeechRecognitionStatus =
  | "onstart"
  | "onspeechstart"
  | "onspeechend"
  | "error"
  | "onend";

const LoaderLottie = () => {
  return (
    <DotLottieReact
      src="/lotties/Loading spinner simplui.lottie" // public/anims/hero.lottie
      autoplay
      loop
      style={{
        width: "72px",
        height: "72px",
      }}
    />
  );
};

const CallPage = () => {
  const router = useRouter();
  const [loading, setLoading] = useState(false);
  const [shouldPulse, setShouldPulse] = useState(false);
  const [text, setText] = useState("ì‹œì‘í•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!");
  const [status, setStatus] = useState<SpeechRecognitionStatus>("onend");
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const audioObjectRef = useRef<HTMLAudioElement | null>(null);
  const [listening, setListening] = useState(false);
  const [isModalOpen, setIsModalOpen] = useState(false);
  const [isMVideoLoading, setIsMVideoLoading] = useState(true);
  const mVideoRef = useRef<HTMLVideoElement>(null);
  const [gptSpeech, setGptSpeech] = useState(true);
  const [communicationContext, setCommunicationContext] = useState<
    {
      content: string;
      role: "user" | "assistant";
    }[]
  >([]);
  const [chat, setChat] = useState<string[]>([]);
  const [firstChat, setFirstChat] = useState<FirstChat | null>(null);
  const [turn, setTurn] = useState(0);
  const scrollRef = useRef<HTMLDivElement>(null);

  const handleMVideoCanPlay = () => {
    console.log("ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.");
    setIsMVideoLoading(false);
  };

  const handleMVideoCanPlayAndPlay = () => {
    if (mVideoRef.current) {
      mVideoRef.current.play().catch((error) => {
        console.error("ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", error);
        handleMVideoCanPlay();
      });
    }
  };

  const fetchFirstChat = async () => {
    try {
      const response = await customAxios.get(
        "/api/simulation/voice/firstTurn",
        {
          params: {
            type: "ë³´ì´ìŠ¤í”¼ì‹±",
          },
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${useAuthStore.getState().accessToken}`,
          },
        }
      );

      if (response.status !== 200) {
        throw new Error("ì²« ë²ˆì§¸ ì±„íŒ…ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }
      return response.data;
    } catch (error) {
      console.error("ì²« ë²ˆì§¸ ì±„íŒ… ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨:", error);
      alert("ì²« ë²ˆì§¸ ì±„íŒ…ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
      return null;
    }
  };

  const playAudio = (data: FirstChat) => {
    console.log("ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ:", data);
    const audioData = data;

    console.log("ì˜¤ë””ì˜¤ ë°ì´í„°:", audioData);

    // base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
    const byteString = atob(
      audioData.voiceSpeech.replace(/^data:audio\/mpeg;base64,/, "")
    );
    const byteArray = new Uint8Array(byteString.length);
    for (let i = 0; i < byteString.length; i++) {
      byteArray[i] = byteString.charCodeAt(i);
    }
    const blob = new Blob([byteArray], { type: "audio/mpeg" });

    const audioUrl = URL.createObjectURL(blob);
    const audio = new Audio(audioUrl);
    audioObjectRef.current = audio; // ì˜¤ë””ì˜¤ ê°ì²´ ì €ì¥
    audio.addEventListener("canplaythrough", () => {
      audio.play();
      if (mVideoRef.current) {
        mVideoRef.current.play().catch((error) => {
          console.error("ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", error);
          handleMVideoCanPlay();
        });
      }
    });

    console.log("ì˜¤ë””ì˜¤ ì¬ìƒ:", audioData.speech);
    setCommunicationContext((prev) => [
      ...prev,
      { content: audioData.speech, role: "assistant" },
    ]);
    setChat((prev) => [...prev, audioData.speech]);
    setLoading(false); // ì˜¤ë””ì˜¤ ì¬ìƒì´ ëë‚˜ë©´ ë¡œë”© ìƒíƒœ í•´ì œ
    audio.onended = () => {
      setGptSpeech(false); // GPT ìŒì„± ì¬ìƒ ìƒíƒœ í•´ì œ
      if (mVideoRef.current) {
        mVideoRef.current.pause();
        mVideoRef.current.currentTime = 0; // ë¹„ë””ì˜¤ ì´ˆê¸°í™”
      }
    }; // ì˜¤ë””ì˜¤ ì¬ìƒì´ ëë‚˜ë©´ ë¡œë”© ìƒíƒœ í•´ì œ
    setText(`ğŸ¤– "${audioData.speech}"`);
  };

  const { mutate: sendMessage } = useMutation({
    mutationFn: async (message: string) => {
      try {
        const response = await customAxios.post(
          "/api/simulation/voice/turn",
          {
            sessionId: firstChat?.sessionId || "",
            turn: turn,
            answer: message,
          },
          {
            headers: {
              "Content-Type": "application/json",
              Authorization: `Bearer ${useAuthStore.getState().accessToken}`,
            },
            responseType: "json", // ê·¸ëŒ€ë¡œ ë‘¬ë„ ë¨
            withCredentials: true,
          }
        );

        if (response.status !== 200) {
          throw new Error("ë©”ì‹œì§€ ì „ì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
        }
        console.log("ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ:", response.data);

        return response.data;
      } catch (error) {
        console.error("ì˜¤ë””ì˜¤ ìš”ì²­ ì‹¤íŒ¨:", error);
        throw error;
      }
    },
    onSuccess: (data) => {
      playAudio(data);
    },
    onError: (error) => {
      console.error("ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨:", error);
      setText("âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨");
    },
  });

  const startListening = () => {
    if (!recognitionRef.current) return;

    try {
      recognitionRef.current.start();
      setListening(true);
      setShouldPulse(true); // ë¹„ë””ì˜¤ ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
      // setStatus("ğŸŸ¢ ì¸ì‹ ì‹œì‘ë¨");
      setStatus("onstart");
      setText("ğŸ§ ë“£ëŠ” ì¤‘ì…ë‹ˆë‹¤. ë§í•´ë³´ì„¸ìš”!");
    } catch (err) {
      console.error("ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:", err);
    }
  };

  useEffect(() => {
    if (typeof window === "undefined") return;

    const SpeechRecognition =
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      window.SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
    recognition.continuous = false;

    recognition.onstart = () => {
      // setStatus("ğŸŸ¢ ì¸ì‹ ì‹œì‘ë¨");
      setStatus("onstart");
      setShouldPulse(true);
    };

    recognition.onspeechstart = () => {
      // setStatus("ğŸ—£ï¸ ë§í•˜ëŠ” ì¤‘...");
      setStatus("onspeechstart");
      setShouldPulse(true);
    };

    recognition.onspeechend = () => {
      // setStatus("ğŸ¤« ë§ ë©ˆì¶¤, ì¸ì‹ ì¤‘...");
      setStatus("onspeechend");
      setShouldPulse(false);
      recognition.stop(); // ìë™ìœ¼ë¡œ ì¸ì‹ ì¢…ë£Œ
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      // setStatus("âœ… ì¸ì‹ ê²°ê³¼ ìˆ˜ì‹ ë¨");
      const transcript = event.results[0][0].transcript;
      const confidence = event.results[0][0].confidence;

      setCommunicationContext((prev) => [
        ...prev,
        { content: transcript, role: "user" },
      ]);
      setText("ì‘ë‹µì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤");
      setLoading(true); // ë¡œë”© ìƒíƒœë¡œ ë³€ê²½
      setListening(false); // ìŒì„± ì¸ì‹ ìƒíƒœ í•´ì œ
      setShouldPulse(false); // ë¹„ë””ì˜¤ ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€
      console.log("ì¸ì‹ëœ í…ìŠ¤íŠ¸:", transcript, "ì‹ ë¢°ë„:", confidence);
      sendMessage(transcript); // ë©”ì‹œì§€ ì „ì†¡
      recognition.stop(); // ì¸ì‹ ì¢…ë£Œ
    };

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    recognition.onerror = (event: any) => {
      // setStatus("ğŸ”´ ì˜¤ë¥˜ ë°œìƒ");
      setStatus("error");
      setShouldPulse(false);
    };

    recognition.onend = () => {
      // setStatus("ğŸ”µ ì¸ì‹ ì¢…ë£Œë¨");
      setStatus("onend");
      setShouldPulse(false);
    };

    recognitionRef.current = recognition;
  }, [sendMessage]);

  useEffect(() => {
    const fetchInitialChat = async () => {
      const firstChat = await fetchFirstChat();
      console.log("ì²« ë²ˆì§¸ ì±„íŒ…:", firstChat);
      if (firstChat) {
        playAudio(firstChat);
        setFirstChat(firstChat);
        setCommunicationContext((prev) => [
          ...prev,
          { content: firstChat.speech, role: "assistant" },
        ]);
        setTurn(firstChat.turn || 0);
      }
    };

    fetchInitialChat();

    // const utterance = new SpeechSynthesisUtterance(
    //   "ì•ˆë…•í•˜ì„¸ìš”, ì´ê²ƒì€ ì›¹ APIì˜ TTS ê¸°ëŠ¥ì…ë‹ˆë‹¤."
    // );
    // utterance.lang = "ko-KR"; // í•œêµ­ì–´
    // utterance.rate = 1; // ê¸°ë³¸ ì†ë„
    // utterance.pitch = 1; // ê¸°ë³¸ ìŒì¡°
    // speechSynthesis.speak(utterance);
  }, []);

  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollIntoView({ behavior: "smooth" });
    }
  }, [chat, loading]);

  return (
    <Container>
      <Header>
        <div
          style={{
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            cursor: "pointer",
          }}
          onClick={() => router.back()}
        >
          <LeftChevronIcon fill="white" />
        </div>
        <div
          style={{
            display: "flex",
            alignItems: "center",
            justifyContent: "center",
            gap: "6px",
          }}
        >
          <ProfileIcon />
          <div
            style={{
              ...TYPOGRAPHY.body1.semiBold,
              color: COLORS.grayscale[100],
            }}
          >
            1588-0000
          </div>
        </div>
      </Header>
      <NoScrollContainer>
        <VideoContainer>
          {firstChat && isMVideoLoading && (
            <div
              style={{
                position: "absolute",
                width: "100%",
                height: "100%",
                display: "flex",
                justifyContent: "center",
                alignItems: "center",
                backgroundColor: COLORS.grayscale[1300],
                borderRadius: "10px",
                zIndex: 1,
              }}
            >
              <LoaderLottie />
            </div>
          )}
          <VideoEl
            ref={mVideoRef}
            loop
            preload="auto"
            playsInline
            // ë” ì¼ì°: onLoadedMetadata / í”„ë ˆì„ ì¤€ë¹„: onLoadedData / ì‹¤ì œ ì¬ìƒ ì‹œì‘: onPlaying
            onLoadedData={() => handleMVideoCanPlay()}
            onError={(e) => {
              console.error("video error", e);
              handleMVideoCanPlay();
            }}
          >
            <source src="/videos/prosecutors.mp4" type="video/mp4" />
            ë¹„ë””ì˜¤ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.
          </VideoEl>
        </VideoContainer>
        <ChatContainer>
          {chat.map((message, index) => (
            <ChatMessage
              key={index}
              ref={scrollRef}
              style={{ animation: "fadeIn 0.5s" }}
            >
              <Typewriter
                typingSpeed={20}
                textArray={[message]}
                // onTypingStart={() => {
                //   // ë¹„ë””ì˜¤ ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
                //   if (mVideoRef.current && !isMVideoLoading && gptSpeech) {
                //     mVideoRef.current.play().catch((error) => {
                //       console.error("ë¹„ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", error);
                //       handleMVideoCanPlay();
                //     });
                //   }
                // }}
                // onComplete={() => {
                //   if (index === chat.length - 1 && gptSpeech) {
                //     // ë¹„ë””ì˜¤ ë©ˆì¶”ê¸°
                //     if (mVideoRef.current) {
                //       mVideoRef.current.pause();
                //       mVideoRef.current.currentTime = 0; // ë¹„ë””ì˜¤ ì´ˆê¸°í™”
                //     }
                //   }
                // }}
              />
            </ChatMessage>
          ))}
          {loading && (
            <ChatMessage ref={scrollRef} style={{ animation: "fadeIn 0.5s" }}>
              <WaveText
                style={{
                  ...TYPOGRAPHY.body1.regular,
                  color: COLORS.grayscale[100],
                }}
              >
                ìƒëŒ€ë°© ë§ ê¸°ë¡ ì¤‘...
              </WaveText>
            </ChatMessage>
          )}
          {/* <ChatMessage>
            <Typewriter
              typingSpeed={20}
              // ë§ˆì§€ë§‰ì— ì˜¤ëŠ” ''ì€ ì‚­ì œ
              textArray={[
                `ì•ˆë…•í•˜ì„¸ìš”, ì„œìš¸ì¤‘ì•™ì§€ê²€ ì´ìƒì²  ìˆ˜ì‚¬ê´€ì…ë‹ˆë‹¤.í˜¹ì‹œ ìµœê·¼ì— ë³¸ì¸ ëª…ì˜ë¡œ ê°œì„¤ëœ ê³„ì¢Œê°€ ë²”ì£„ì— ì‚¬ìš©ëë‹¤ëŠ” ì—°ë½ ë°›ìœ¼ì‹  ì  ìˆìŠµë‹ˆê¹Œ?`,
              ]}
              onComplete={() => {}}
            />
          </ChatMessage> */}
        </ChatContainer>
      </NoScrollContainer>
      <ButtonContainer>
        {listening && (
          <div
            style={{
              ...TYPOGRAPHY.body1.regular,
              color: COLORS.grayscale[100],
              position: "absolute",
              top: "50%",
              left: "50%",
              transform: "translate(-50%,-50%)",
            }}
          >
            {"ë“£ëŠ” ì¤‘..."}
          </div>
        )}
        <Button
          style={{ backgroundColor: COLORS.caution.red[300] }}
          onClick={() => {
            setIsModalOpen(true);
            if (audioObjectRef.current) {
              audioObjectRef.current.pause();
              audioObjectRef.current.currentTime = 0; // ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
            }
            if (recognitionRef.current) {
              recognitionRef.current.abort(); // ìŒì„± ì¸ì‹ ì¤‘ì§€
            }
            setListening(false); // ìŒì„± ì¸ì‹ ìƒíƒœ í•´ì œ
            setShouldPulse(false); // ë¹„ë””ì˜¤ ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€
            setText("ì‹œë®¬ë ˆì´ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. í›ˆë ¨ì„ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ?");
            setCommunicationContext([]); // ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”
            setGptSpeech(false); // GPT ìŒì„± ì¬ìƒ ìƒíƒœ í•´ì œ
            setLoading(false); // ë¡œë”© ìƒíƒœ í•´ì œ
            if (mVideoRef.current) {
              mVideoRef.current.pause(); // ë¹„ë””ì˜¤ ì¼ì‹œ ì •ì§€
              mVideoRef.current.currentTime = 0; // ë¹„ë””ì˜¤ ì´ˆê¸°í™”
            }
            // setIsMVideoLoading(true); // ë¹„ë””ì˜¤ ë¡œë”© ìƒíƒœë¡œ ì„¤ì •
            if (recognitionRef.current) {
              recognitionRef.current.onend = () => {
                setStatus("onend");
                setShouldPulse(false);
              }; // ìŒì„± ì¸ì‹ ì¢…ë£Œ ìƒíƒœë¡œ ì„¤ì •
            }
          }}
        >
          <BigXIcon />
        </Button>
        <Button
          onClick={() => {
            // í˜„ì¬ ì˜¤ë””ì˜¤ ì¬ìƒì´ ìˆë‹¤ë©´ ì¤‘ì§€
            if (audioObjectRef.current) {
              audioObjectRef.current.pause();
              audioObjectRef.current = null; // ì˜¤ë””ì˜¤ ê°ì²´ ì´ˆê¸°í™”
              // audioObjectRef.current.currentTime = 0; // ì˜¤ë””ì˜¤ ì´ˆê¸°í™”
              setGptSpeech(false); // GPT ìŒì„± ì¬ìƒ ìƒíƒœ í•´ì œ
            }

            if (mVideoRef.current) {
              mVideoRef.current.pause(); // ë¹„ë””ì˜¤ ì¼ì‹œ ì •ì§€
              mVideoRef.current.currentTime = 0; // ë¹„ë””ì˜¤ ì´ˆê¸°í™”
            }

            // í˜„ì¬ ìŒì„± ì¸ì‹ì´ ì§„í–‰ ì¤‘ì´ë©´ ì¤‘ì§€
            if (recognitionRef.current && listening) {
              recognitionRef.current.stop();
              setListening(false);
              setShouldPulse(false); // ë¹„ë””ì˜¤ ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€
              setLoading(false); // ë¡œë”© ìƒíƒœ í•´ì œ
              setStatus("onend");
              return;
            }
            startListening();
          }}
          style={{
            backgroundColor: listening
              ? COLORS.grayscale[100]
              : COLORS.grayscale[800],
          }}
        >
          <MicIcon fill={listening ? COLORS.grayscale[1300] : "white"} />
        </Button>
      </ButtonContainer>
      <Modal style={{ display: isModalOpen ? "flex" : "none" }}>
        <MessageBox>
          <div>
            ì§€ê¸ˆ ë‚˜ê°€ë©´ ì§„í–‰ ì¤‘ì¸ ì‹œë®¬ë ˆì´ì…˜ì˜ <br />
            ì§„í–‰ë„ì™€ ë¶„ì„ì´ ì´ˆê¸°í™”ë  ìˆ˜ ìˆì–´ìš”. <br />
            ê·¸ë˜ë„ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?
          </div>
          <div
            style={{
              width: "100%",
              display: "flex",
              justifyContent: "center",
              alignItems: "center",
              gap: "8px",
            }}
          >
            <MessageBoxButton
              style={{
                ...TYPOGRAPHY.body1.medium,
                backgroundColor: COLORS.caution.red[300],
                color: COLORS.grayscale[100],
              }}
              onClick={() => {
                router.push("/");
              }}
            >
              ë‚˜ê°€ê¸°
            </MessageBoxButton>
            <MessageBoxButton
              style={{
                ...TYPOGRAPHY.body1.medium,
                backgroundColor: COLORS.grayscale[1100],
                color: COLORS.grayscale[100],
              }}
              onClick={() => {
                setIsModalOpen(false);
              }}
            >
              í›ˆë ¨ ê³„ì†í•˜ê¸°
            </MessageBoxButton>
          </div>
        </MessageBox>
      </Modal>
    </Container>
  );
};

export default CallPage;

const Container = styled.main`
  background-color: ${COLORS.grayscale[1300]};
  width: 100%;
  height: calc(var(--vh, 1vh) * 100);
  position: relative;
  display: flex;
  justify-content: flex-start;
  align-items: center;
  flex-direction: column;
  padding-top: 63px;
  overflow-x: hidden;
  overflow-y: hidden;
  -webkit-overflow-scrolling: touch;
  &::-webkit-scrollbar {
    display: none;
  }
  scrollbar-width: none;
  -ms-overflow-style: none; /* IE and Edge */
`;

const Header = styled.div`
  width: 100%;
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  display: flex;
  justify-content: flex-start;
  align-items: center;
  overflow: hidden;
  padding-right: 16px;
  padding-left: 16px;
  height: 57px;
  background-color: transparent;
  margin-bottom: 6px;
  gap: 20px;
`;

const VideoEl = styled.video`
  inset: 0;
  /* width: 100%;
  height: 100%; */
  object-fit: cover;
`;

const VideoContainer = styled.div`
  width: 100%;
  height: 346px;
  display: flex;
  justify-content: center;
  align-items: center;
  position: relative;
  overflow: hidden;
  background-color: ${COLORS.grayscale[1300]};
  border-radius: 10px;
`;

const ButtonContainer = styled.div`
  position: relative;
  width: 100%;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 0 16px;
  margin-top: 16px;
  margin-bottom: 26px;
  gap: 135px;
`;

const Button = styled.button`
  width: 80px;
  height: 80px;
  display: flex;
  align-items: center;
  justify-content: center;
  cursor: pointer;
  z-index: 2;
  border-radius: 50%;
`;

const ChatContainer = styled.div`
  flex: 1;
  width: 100%;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  overflow-y: auto;
  background-color: ${COLORS.grayscale[1300]};
  color: ${COLORS.grayscale[100]};
  font-size: ${TYPOGRAPHY.body1.regular.fontSize};
`;

const ChatMessage = styled.div`
  width: 100%;
  padding-top: 20px;
  word-break: break-word;
  font-size: 16px;
  line-height: 1.4;
  letter-spacing: -0.5%;
  color: ${COLORS.grayscale[100]};
`;

const Modal = styled.div`
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: rgba(0, 0, 0, 0.5);
  z-index: 1000;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 0 26px;
`;

const MessageBox = styled.div`
  width: 100%;
  background-color: white;
  color: ${COLORS.grayscale[1300]};
  border-radius: 15px;
  padding: 18px;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  text-align: center;
  gap: 16px;
`;

const MessageBoxButton = styled.div`
  flex: 1;
  width: 100%;
  height: 46px;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 0 16px;
  cursor: pointer;
  border-radius: 50px;
`;

const WaveText = styled.h1`
  font-size: 64px;
  font-weight: bold;
  background: linear-gradient(
    270deg,
    #ff4d4d,
    #ff9a3c,
    #ffd93c,
    #3cff90,
    #3cc2ff,
    #a43cff,
    #ff4da6,
    #ff4d4d
  );
  background-size: 1600% 1600%;
  background-clip: text;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  animation: wave 8s ease infinite;

  @keyframes wave {
    0% {
      background-position: 0% 50%;
    }
    50% {
      background-position: 100% 50%;
    }
    100% {
      background-position: 0% 50%;
    }
  }
`;

const NoScrollContainer = styled.div`
  width: 100%;
  padding: 0 16px;
  flex: 1;
  position: relative;
  overflow-y: auto;
  overflow-x: hidden;
  -webkit-overflow-scrolling: touch;
  &::-webkit-scrollbar {
    display: none;
  }
  scrollbar-width: none;
  -ms-overflow-style: none; /* IE and Edge */
`;
